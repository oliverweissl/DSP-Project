{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:39:16.637125300Z",
     "start_time": "2024-01-14T12:39:05.975559300Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "from transformers.utils.notebook import NotebookProgressCallback\n",
    "from pipeline import CustomTrainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fac013c90fd605",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b53ab5f3907700d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:39:16.903110600Z",
     "start_time": "2024-01-14T12:39:16.643117500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = [\"google/flan-t5-small\", \"TheBloke/Llama-2-7B-GGUF\", \"bigscience/bloom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f3950894b367b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:39:36.279588900Z",
     "start_time": "2024-01-14T12:39:30.631280Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload = True,\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"google/flan-t5-small\",\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\", trust_remote_code=True)\n",
    "\n",
    "dataset = load_dataset('csv',split='train',data_files=\"dataset_complete.csv\")\n",
    "dataset = dataset.train_test_split(test_size=0.05)\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a68f0608bd188e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:00:42.350680200Z",
     "start_time": "2024-01-14T12:00:42.063684200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "    \n",
    "def eval_metric(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "726a99c4fa03f2e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:00:42.989686300Z",
     "start_time": "2024-01-14T12:00:42.641685100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer_factory = CustomTrainer(tokenizer=tokenizer, tpe=\"flint\", model=model, dataset=dataset, eval=eval_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591aa03bc45d4475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:00:44.679680900Z",
     "start_time": "2024-01-14T12:00:43.359698Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67c0dd2407c4a7f9c59157fef5d958f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1046 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30d1099cf6742c5a9501b98c22263fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = trainer_factory.get_trainer()\n",
    "trainer.callback_handler.callbacks.pop()\n",
    "trainer.add_callback(NotebookProgressCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2052863aa016be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T12:01:33.859684200Z",
     "start_time": "2024-01-14T12:00:44.684696Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\Oliver\\PycharmProjects\\DSP-Project\\venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Oliver\\PycharmProjects\\DSP-Project\\venv\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:318: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3920' max='3920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3920/3920 1:15:27, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.029959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.018191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.017402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.016483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.015986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.015970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsp",
   "language": "python",
   "name": "dsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
